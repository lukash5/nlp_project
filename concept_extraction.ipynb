{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import requests\n",
    "from itertools import combinations\n",
    "from typing import Dict, List, Optional, Set, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import xmltodict\n",
    "from numpy.linalg import norm\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that necessary nltk resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve data\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_primary_name(names: Union[List[Dict[str, str]], Dict[str, str]]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Retrieves the primary name from the given names and formats it to lowercase with underscores.\n",
    "\n",
    "    Args:\n",
    "        names (Union[List[Dict[str, str]], Dict[str, str]]): The list or dict containing name information.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The formatted primary name, or None if not found.\n",
    "    \"\"\"\n",
    "    if isinstance(names, list):\n",
    "        for name in names:\n",
    "            if name.get('@type') == 'primary':\n",
    "                primary_name = name.get('@value')\n",
    "                return primary_name.lower().replace(' ', '_')\n",
    "    elif isinstance(names, dict) and names.get('@type') == 'primary':\n",
    "        primary_name = names.get('@value')\n",
    "        return primary_name.lower().replace(' ', '_')\n",
    "    return None\n",
    "\n",
    "def retrieve_comments(index: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieves comments for the board game with the given index from the BoardGameGeek API and formats the game name\n",
    "\n",
    "    Args:\n",
    "        index (int): The index of the board game.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: comments with the formatted game name as keys\n",
    "    \"\"\"\n",
    "    URL = f\"https://boardgamegeek.com/xmlapi2/thing?id={index}&type=boardgame&comments=1\"\n",
    "    response = requests.get(URL)\n",
    "    data = xmltodict.parse(response.content)\n",
    "    \n",
    "    game_name = get_primary_name(data[\"items\"][\"item\"]['name'])\n",
    "\n",
    "    comments = []\n",
    "    if 'items' in data and 'item' in data['items']:\n",
    "        item = data['items']['item']\n",
    "        if 'comments' in item and 'comment' in item['comments']:\n",
    "            for comment in item['comments']['comment']:\n",
    "                comments.append({game_name: comment['@value']})\n",
    "\n",
    "    return pd.DataFrame(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mighty_empires</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Played it a long time ago. I have now only a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I loved this game as a teenager, but the compl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nice pieces and tiles. Basic and easy rules, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A game from my childhood. We had a massive map...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Use the pieces for War of the Ring!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Loved this game! Wish they would reprint..in i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Several extra Metal Miniatures, extra White Dw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This game just seems to have missed the mark i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>As a stand alone I really enjoyed playing this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It's a good campaign generator for Warhammer b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I play it as the campaign system for Warhammer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Although the theme is great, the rules are a b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Some very cool ideas (and the game looks terri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Unfortunately on 26-11-2009, BGG were instruct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I'm glad GW re-released the metal parts as cam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       mighty_empires\n",
       "0   Played it a long time ago. I have now only a f...\n",
       "1   I loved this game as a teenager, but the compl...\n",
       "2   Nice pieces and tiles. Basic and easy rules, a...\n",
       "3   A game from my childhood. We had a massive map...\n",
       "4                 Use the pieces for War of the Ring!\n",
       "5   Loved this game! Wish they would reprint..in i...\n",
       "6   Several extra Metal Miniatures, extra White Dw...\n",
       "7   This game just seems to have missed the mark i...\n",
       "8   As a stand alone I really enjoyed playing this...\n",
       "9   It's a good campaign generator for Warhammer b...\n",
       "10  I play it as the campaign system for Warhammer...\n",
       "11  Although the theme is great, the rules are a b...\n",
       "12  Some very cool ideas (and the game looks terri...\n",
       "13  Unfortunately on 26-11-2009, BGG were instruct...\n",
       "14  I'm glad GW re-released the metal parts as cam..."
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_comments(52).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event concept extraction algorithm\n",
    "----\n",
    "\n",
    "The algorithm for capturing event concepts matches object concepts with normalized verb chunks. This is achieved by utilizing a parse graph that maps all the multi-word expressions contained in the knowledge bases.\n",
    "1.\tMatch Object and Verb Phrases:\n",
    "\t- The algorithm searches for matches between the object concepts and the normalized verb phrases.\n",
    "2.\tUtilize a Parse Graph:\n",
    "\t- A directed, unweighted parse graph is used to quickly detect multi-word concepts without performing an exhaustive search through all possible word combinations that can form a commonsense concept.\n",
    "3.\tRemove Redundant Terms:\n",
    "\t- Single-word concepts, such as “house,” that already appear in the clause as part of a multi-word concept, like “beautiful house,” are considered pleonastic (providing redundant information) and are discarded.\n",
    "4.\tExtract Event Concepts:\n",
    "\t- The algorithm extracts event concepts such as “go market,” “buy some fruits,” “buy fruits,” and “buy vegetables.”\n",
    "\t- These event concepts represent Script-Based Object Concepts (SBoCs) and can be fed into a commonsense reasoning algorithm for further processing.\n",
    "\n",
    "---- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_concept_extraction(sentence: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extracts event concepts from a given sentence.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): sentence to process\n",
    "\n",
    "    Returns:\n",
    "        List[str]: extracted event concepts\n",
    "    \"\"\"\n",
    "    concepts: Set[str] = set()  # initialize an empty set to store unique concepts\n",
    "    doc = nlp(sentence)  # process the sentence with spaCy\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        # identify all verbs in the sentence\n",
    "        verbs = [token for token in sent if token.pos_ == 'VERB']\n",
    "        # identify all noun phrases in the sentence\n",
    "        noun_phrases = list(sent.noun_chunks)\n",
    "\n",
    "        for verb in verbs:\n",
    "            # stem the verb\n",
    "            stemmed_verb = verb.lemma_\n",
    "            # find noun phrases associated with the verb\n",
    "            associated_nouns = [np for np in noun_phrases if np.root.head == verb]\n",
    "\n",
    "            for np in associated_nouns:\n",
    "                # extract adjectives in the noun phrase\n",
    "                adjectives = [token.text for token in np if token.pos_ == 'ADJ']\n",
    "                if len(np) > 1:\n",
    "                    # if the noun phrase contains more than one word, form a concept with the verb and noun phrase\n",
    "                    concept = f\"{stemmed_verb} {' '.join([token.text for token in np])}\"\n",
    "                    if adjectives:\n",
    "                        concept += f\" {' '.join(adjectives)}\"\n",
    "                    concepts.add(concept)\n",
    "                else:\n",
    "                    # handle single-word noun phrases\n",
    "                    single_word_concept = np.text\n",
    "                    if not any(single_word_concept in concept for concept in concepts):\n",
    "                        concept = f\"{stemmed_verb} {single_word_concept}\"\n",
    "                        if adjectives:\n",
    "                            concept += f\" {' '.join(adjectives)}\"\n",
    "                        concepts.add(concept)\n",
    "\n",
    "        for np in noun_phrases:\n",
    "            # handle noun phrases associated with auxiliary verbs\n",
    "            if np.root.head.pos_ == 'AUX':\n",
    "                adjectives = [token.text for token in np if token.pos_ == 'ADJ']\n",
    "                concept = f\"be {' '.join([token.text for token in np])}\"\n",
    "                if adjectives:\n",
    "                    concept += f\" {' '.join(adjectives)}\"\n",
    "                concepts.add(concept)\n",
    "\n",
    "    return list(concepts)\n",
    "\n",
    "def extract_concepts_from_text(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extracts event concepts from a given text by splitting it into sentences first\n",
    "\n",
    "    Args:\n",
    "        text (str): text to process\n",
    "\n",
    "    Returns:\n",
    "        List[str]: extracted event concepts\n",
    "    \"\"\"\n",
    "    all_concepts = set()\n",
    "    doc = nlp(text)\n",
    "    for sent in doc.sents:\n",
    "        concepts = event_concept_extraction(sent.text)\n",
    "        all_concepts.update(concepts)\n",
    "    return list(all_concepts)\n",
    "\n",
    "def extract_concepts_from_series(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Extracts event concepts from a pandas Series\n",
    "\n",
    "    Args:\n",
    "        series (pd.Series): Series to process\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: extracted event concepts\n",
    "    \"\"\"\n",
    "    all_concepts_series = series.apply(lambda text: extract_concepts_from_text(str(text)))\n",
    "    return all_concepts_series\n",
    "\n",
    "def extract_concepts_from_dataframe(df: pd.DataFrame, text_columns: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts event concepts from specified columns of a pandas DataFrame\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to process\n",
    "        text_columns (List[str]): column names containing text data to process\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: extracted event concepts in corresponding new columns\n",
    "    \"\"\"\n",
    "    result_df = df.copy()\n",
    "    for column in text_columns:\n",
    "        result_df[f\"{column}_concepts\"] = extract_concepts_from_series(df[column])\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare comments for a board game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mighty_empires</th>\n",
       "      <th>mighty_empires_concepts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Played it a long time ago. I have now only a f...</td>\n",
       "      <td>[leave only a few spare parts few spare, play ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I loved this game as a teenager, but the compl...</td>\n",
       "      <td>[mean the complexity, doubt I, love this game,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nice pieces and tiles. Basic and easy rules, a...</td>\n",
       "      <td>[run ancient or medieval campaigns ancient med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A game from my childhood. We had a massive map...</td>\n",
       "      <td>[have We, work the game, have a massive map ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Use the pieces for War of the Ring!</td>\n",
       "      <td>[use the pieces]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Loved this game! Wish they would reprint..in i...</td>\n",
       "      <td>[reprint they]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Several extra Metal Miniatures, extra White Dw...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This game just seems to have missed the mark i...</td>\n",
       "      <td>[have a massive head start massive, miss the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>As a stand alone I really enjoyed playing this...</td>\n",
       "      <td>[play this, enjoy I, make numerous house ruled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It's a good campaign generator for Warhammer b...</td>\n",
       "      <td>[be a good campaign generator good, be nothing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I play it as the campaign system for Warhammer...</td>\n",
       "      <td>[play I, play it]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Although the theme is great, the rules are a b...</td>\n",
       "      <td>[be the rules, be the theme]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Some very cool ideas (and the game looks terri...</td>\n",
       "      <td>[look Some very cool ideas cool, spend you, sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Unfortunately on 26-11-2009, BGG were instruct...</td>\n",
       "      <td>[break customers, be The games, attitude the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I'm glad GW re-released the metal parts as cam...</td>\n",
       "      <td>[release the metal parts, help The added varie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       mighty_empires  \\\n",
       "0   Played it a long time ago. I have now only a f...   \n",
       "1   I loved this game as a teenager, but the compl...   \n",
       "2   Nice pieces and tiles. Basic and easy rules, a...   \n",
       "3   A game from my childhood. We had a massive map...   \n",
       "4                 Use the pieces for War of the Ring!   \n",
       "5   Loved this game! Wish they would reprint..in i...   \n",
       "6   Several extra Metal Miniatures, extra White Dw...   \n",
       "7   This game just seems to have missed the mark i...   \n",
       "8   As a stand alone I really enjoyed playing this...   \n",
       "9   It's a good campaign generator for Warhammer b...   \n",
       "10  I play it as the campaign system for Warhammer...   \n",
       "11  Although the theme is great, the rules are a b...   \n",
       "12  Some very cool ideas (and the game looks terri...   \n",
       "13  Unfortunately on 26-11-2009, BGG were instruct...   \n",
       "14  I'm glad GW re-released the metal parts as cam...   \n",
       "\n",
       "                              mighty_empires_concepts  \n",
       "0   [leave only a few spare parts few spare, play ...  \n",
       "1   [mean the complexity, doubt I, love this game,...  \n",
       "2   [run ancient or medieval campaigns ancient med...  \n",
       "3   [have We, work the game, have a massive map ma...  \n",
       "4                                    [use the pieces]  \n",
       "5                                      [reprint they]  \n",
       "6                                                  []  \n",
       "7   [have a massive head start massive, miss the m...  \n",
       "8   [play this, enjoy I, make numerous house ruled...  \n",
       "9   [be a good campaign generator good, be nothing...  \n",
       "10                                  [play I, play it]  \n",
       "11                       [be the rules, be the theme]  \n",
       "12  [look Some very cool ideas cool, spend you, sp...  \n",
       "13  [break customers, be The games, attitude the c...  \n",
       "14  [release the metal parts, help The added varie...  "
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = retrieve_comments(52)\n",
    "concepts = extract_concepts_from_dataframe(comments, [comments.columns[0]])\n",
    "# concepts.to_csv(f\"./{concepts.columns[0]}.csv\")\n",
    "concepts.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load embedding for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(file_path: str) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Loads word embeddings from a file\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the embeddings file\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, np.ndarray]: word embeddings\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(' ')\n",
    "            word = parts[0]\n",
    "            vector = np.array(parts[1:], dtype=float)\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "def get_combined_embedding(words: List[str], embeddings: Dict[str, np.ndarray]) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Computes the combined embedding for a list of words\n",
    "\n",
    "    Args:\n",
    "        words (List[str]): List of words.\n",
    "        embeddings (Dict[str, np.ndarray]): word embeddings.\n",
    "\n",
    "    Returns:\n",
    "        Optional[np.ndarray]: Combined embedding vector, or None if no valid embeddings found\n",
    "    \"\"\"\n",
    "    valid_embeddings = [embeddings.get(word) for word in words if word in embeddings]\n",
    "    if not valid_embeddings:\n",
    "        return None\n",
    "    return np.mean(valid_embeddings, axis=0)\n",
    "\n",
    "\n",
    "def process_concepts_from_dataframe(df: pd.DataFrame, column_name: str, embeddings: Dict[str, np.ndarray]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes concepts from a DataFrame column and computes their embeddings\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): original sentences and concepts\n",
    "        embeddings (Dict[str, np.ndarray]): word embeddings\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: original sentences, concepts, and their embeddings\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        sentence = row[column_name]\n",
    "        concepts = row[column_name + '_concepts']\n",
    "        concept_embedding = []\n",
    "        num_concepts = 0\n",
    "        for concept in concepts:\n",
    "            words = concept.split()\n",
    "            embedding = get_combined_embedding(words, embeddings)\n",
    "\n",
    "            if embedding is not None:\n",
    "                num_concepts += 1\n",
    "                concept_embedding.append(embedding)\n",
    "\n",
    "        processed_data.append({\n",
    "            'sentence': sentence,\n",
    "            'concept': concepts,\n",
    "            'embedding': concept_embedding,\n",
    "            'num_concepts': num_concepts,\n",
    "        })\n",
    "\n",
    "    result_df = pd.DataFrame(processed_data)\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "embeddings = load_embeddings('./data/numberbatch-en.txt')\n",
    "\n",
    "# Process concepts and compute embeddings\n",
    "concepts = process_concepts_from_dataframe(concepts, concepts.columns[0], embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukas/anaconda3/envs/nlp/lib/python3.12/site-packages/sklearn_extra/cluster/_k_medoids.py:329: UserWarning: Cluster 2 is empty! self.labels_[self.medoid_indices_[2]] may not be labeled with its corresponding cluster (2).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def cluster_concepts(concepts: pd.DataFrame, num_clusters: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clusters each concept using KMedoids separately \n",
    "\n",
    "    Args:\n",
    "        concepts (pd.DataFrame): DataFrame containing concepts and their embeddings.\n",
    "        num_clusters (int): number of clusters\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: clustering results\n",
    "    \"\"\"\n",
    "    clustered_concepts_list = []\n",
    "    \n",
    "    for index, row in concepts.iterrows():\n",
    "        embedding = row['embedding']\n",
    "        concepts = row['concept']\n",
    "        num_concepts = row['num_concepts']\n",
    "\n",
    "        reduced_concepts = []\n",
    "\n",
    "        if num_concepts != 0:\n",
    "            # Perform KMedoids clustering on this set\n",
    "            kmedoids = KMedoids(n_clusters=min(num_clusters, num_concepts), random_state=0).fit(embedding)\n",
    "            labels = kmedoids.labels_\n",
    "\n",
    "            clustered_concepts = {}\n",
    "            for label, concept in zip(labels, concepts):\n",
    "                if label not in clustered_concepts:\n",
    "                    clustered_concepts[label] = []\n",
    "                clustered_concepts[label].append((concept, embedding[concepts.index(concept)]))\n",
    "\n",
    "            for label, items in clustered_concepts.items():\n",
    "                medoid_index = kmedoids.medoid_indices_[label]\n",
    "                reduced_concepts.append(concepts[medoid_index])\n",
    "            \n",
    "        # Add clustering results to a new DataFrame\n",
    "        clustered_concepts_list.append({\n",
    "            'concept': concepts,\n",
    "            'clustered_concepts': reduced_concepts,\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(clustered_concepts_list)\n",
    "\n",
    "# Cluster the concepts and get the reduced concepts\n",
    "reduced_concepts = cluster_concepts(concepts, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the pre-defined classes with keywords\n",
    "\n",
    "\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplified classes\n",
    "class_keywords = {\n",
    "    'luck or alea': ['luck', 'chance', 'alea', 'out of control'],\n",
    "    'bookkeeping': ['bookkeeping', 'manual recording', 'rulebook'],\n",
    "    'downtime': ['downtime', 'waiting', 'unproductive'],\n",
    "    'interaction': ['interaction', 'influence on other players'],\n",
    "    'bash the leader': ['bash the leader', 'sacrifice themself', 'prevent victory'],\n",
    "    'complicated': ['complicated', 'many rules', 'exceptions'],\n",
    "    'complex': ['complex', 'repercussions', 'unpredictable', 'difficult to master'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Use of similarity meassure\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> Optional[float]:\n",
    "    if vec1 is None or vec2 is None:\n",
    "        return None\n",
    "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
    "\n",
    "def compute_similarity(concept: str, class_keywords: Dict[str, List[str]], embeddings: Dict[str, np.ndarray], \n",
    "                       similarity_threshold: float = 0.5, top_n_classes: int = 3) -> Optional[Tuple[str, float]]:\n",
    "    \n",
    "    concept_embedding = get_combined_embedding(concept.split(), embeddings)\n",
    "    if concept_embedding is None:\n",
    "        return None\n",
    "    \n",
    "    similarities = []\n",
    "    for class_name, keywords in class_keywords.items():\n",
    "        class_embedding = get_combined_embedding(keywords, embeddings)\n",
    "        if class_embedding is None:\n",
    "            continue\n",
    "        similarity = cosine_similarity(concept_embedding, class_embedding)\n",
    "        if similarity is not None:\n",
    "            similarities.append((class_name, similarity))\n",
    "    \n",
    "    # Filter classes based on similarity threshold\n",
    "    similarities = [item for item in similarities if item[1] >= similarity_threshold]\n",
    "    # Sort by similarity and get top N\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_classes = similarities[:top_n_classes]\n",
    "    \n",
    "    if not top_classes:\n",
    "        return None\n",
    "            \n",
    "    return top_classes[0]  # Return the best class and its similarity\n",
    "\n",
    "def assign_concepts_to_classes(concepts: pd.DataFrame, class_keywords: Dict[str, List[str]], embeddings: Dict[str, np.ndarray], \n",
    "                               similarity_threshold: float = 0.2, top_n_classes: int = 1) -> pd.DataFrame:\n",
    "    assignment_results = []\n",
    "    for _, row in concepts.iterrows():\n",
    "        concepts = row['clustered_concepts']\n",
    "        assignments = {}\n",
    "        for concept in concepts:\n",
    "            best_class = compute_similarity(concept, class_keywords, embeddings, similarity_threshold, top_n_classes)\n",
    "            assignments[concept] = best_class\n",
    "        \n",
    "        assignment_results.append({\n",
    "            'classified_concepts': assignments \n",
    "        })\n",
    "     \n",
    "    assignment_df = pd.DataFrame(assignment_results)\n",
    "    return assignment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classified_concepts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'leave only a few spare parts few spare': ('d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'love this game': None, 'enjoy it': None, 'se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'run ancient or medieval campaigns ancient me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'have a massive map massive': None, 'work the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'use the pieces': None}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>{'buy two sets': None, 'enjoy this game': ('lu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>{'make which': None, 'take it': None, 'take ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>{'play this': None, 'need new gaming friends n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>{'be it': None, 'be a reasonable system reason...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>{'play this': None, 'be a teenager': None, 'pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  classified_concepts\n",
       "0   {'leave only a few spare parts few spare': ('d...\n",
       "1   {'love this game': None, 'enjoy it': None, 'se...\n",
       "2   {'run ancient or medieval campaigns ancient me...\n",
       "3   {'have a massive map massive': None, 'work the...\n",
       "4                            {'use the pieces': None}\n",
       "..                                                ...\n",
       "95  {'buy two sets': None, 'enjoy this game': ('lu...\n",
       "96  {'make which': None, 'take it': None, 'take ma...\n",
       "97  {'play this': None, 'need new gaming friends n...\n",
       "98  {'be it': None, 'be a reasonable system reason...\n",
       "99  {'play this': None, 'be a teenager': None, 'pl...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign concepts to classes\n",
    "assigned_classes = assign_concepts_to_classes(reduced_concepts, class_keywords, embeddings)\n",
    "\n",
    "# Output the results\n",
    "assigned_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
