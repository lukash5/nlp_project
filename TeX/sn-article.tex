%Version 3 October 2023
% See section 11 of the User Manual for version history
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%======================================================%%
%% to compile with pdflatex/xelatex use pdflatex option %%
%%======================================================%%

%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style


%%Note: the following reference styles support Namedate and Numbered referencing. By default the style follows the most common style. To switch between the options you can add or remove �Numbered� in the optional parenthesis. 
%%The option is available for: sn-basic.bst, sn-vancouver.bst, sn-chicago.bst%  
 
%%\documentclass[sn-nature]{sn-jnl}% Style for submissions to Nature Portfolio journals
%%\documentclass[sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
\documentclass[sn-mathphys-num]{sn-jnl}% Math and Physical Sciences Numbered Reference Style 
%%\documentclass[sn-mathphys-ay]{sn-jnl}% Math and Physical Sciences Author Year Reference Style
%%\documentclass[sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
%%\documentclass[sn-vancouver,Numbered]{sn-jnl}% Vancouver Reference Style
%%\documentclass[sn-apa]{sn-jnl}% APA Reference Style 
%%\documentclass[sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style

%%%% Standard Packages
%%<additional latex packages if required can be included here>

\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%

\usepackage{hyperref}
\usepackage{caption}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Classification based on aspect extraction},
    pdfpagemode=FullScreen,
    }

%%%%

%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published 
%%%%  by Springer Nature. The guidance has been prepared in partnership with 
%%%%  production teams to conform to Springer Nature technical requirements. 
%%%%  Editorial and presentation requirements differ among journal portfolios and 
%%%%  research disciplines. You may find sections in this template are irrelevant 
%%%%  to your work and are empowered to omit any such section if allowed by the 
%%%%  journal you intend to submit to. The submission guidelines and policies 
%%%%  of the journal take precedence. A detailed User Manual is available in the 
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%

%% as per the requirement new theorem styles can be included as shown below
\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
\newtheorem{proposition}[theorem]{Proposition}% 
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%

\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads

\begin{document}
\captionsetup{justification=centering}  % Zentrieren der Caption


\title[Classification based on aspect extraction]{Classification based on aspect extraction}

%%=============================================================%%
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% \author*[1,2]{\fnm{Joergen W.} \spfx{van der} \sur{Ploeg} 
%%  \sfx{IV}}\email{iauthor@gmail.com}
%%=============================================================%%

\author{\fnm{Lukas} \sur{Hirsch}}\email{lukas.hirsch@studenti.unimi.it}

%%==================================%%
%% Sample for unstructured abstract %%
%%==================================%%

\abstract{This study explores the use of semantic parsing techniques to classify user comments on board games. Using a graph-based approach and \textit{ConceptNet} embeddings, the proposed method aims to categorize comments into predefined aspects. The performance of this method is compared to OpenAI's \textit{GPT-4o} model by manually counting classification errors and calculating error rates. The results show that while the \textit{GPT-4o} model achieved higher accuracy in correct classifications, the presented method extracted a significant number of concepts, although many of them lacked semantic relevance. This research highlights the strengths and limitations of both approaches and underscores the challenge of accurately classifying aspects based on natural language.}

% \keywords{keyword1, Keyword2, Keyword3, Keyword4}

%%\pacs[JEL Classification]{D8, H51}

%%\pacs[MSC Classification]{35A01, 65L10, 65L12, 65L20, 65L70}

\maketitle

\section{Introduction}\label{intro}
    In the field of \textit{natural language processing (NLP)}, the ability to semantically parse and understand text is critical for a variety of applications, including sentiment analysis and reasoning. Semantic parsing, which involves breaking down text into multi-word concepts, improves the understanding and interpretation of textual data. This can be achieved through phrase structure grammars or statistical, training-based algorithms. Recent advances, such as transformational models like \textit{BERT} \cite{DBLP:journals/corr/abs-1810-04805}, have shown great promise in this area.\\\\
    This project aims to classify user comments on the board game \textit{Mighty Empires} \cite{mightyempires1990} into predefined categories using a graph-based technique combined with embeddings from the multilingual knowledge graph \textit{ConceptNet} \cite{DBLP:journals/corr/SpeerCH16}. To evaluate the effectiveness of this approach, it will be compared to the \textit{GPT-4o} \cite{openai_gpt4o} model from OpenAI. The dataset obtained from \textit{BoardGameGeek} \cite{BoardGameGeek} contains 100 user comments on \textit{Mighty Empires}. The predefined categories are based on the Italian definition of \textit{Goblinpedia} \cite{goblinpedia} and include various aspects such as luck, accounting, downtime, interaction, and more. The primary objective is to compare the performance of the unsupervised method presented in this study with that of the \textit{GPT-4o} model, highlighting the strengths and limitations of each.\\\\
    The experimental results show that the \textit{GPT-4o} model significantly outperforms the proposed method in terms of correct classifications. In particular, the \textit{GPT-4o} model achieved a higher number of correct classifications with fewer errors, demonstrating the advantages of training-based algorithms. In contrast, while the unsupervised method extracted a significant number of concepts, many lacked semantic relevance, resulting in incorrect classifications. These results underscore the challenge of accurately classifying aspects based on user comments and highlight the need for further refinement of semantic parsing techniques. 

\section{Dataset}\label{data}
    The dataset used is provided by \textit{BoardGameGeek (BGG)} \cite{BoardGameGeek}, a comprehensive database of board games and the global community of gamers. Users contribute data, including statistics and ratings, which assess the popularity of each game based on several criteria. These criteria include an overall rating, the number of users who voted for the game, and the community's opinion of the game's playability with different numbers of players. In addition, BGG allows access to user comments on games, which is the only part used for this project. Data was retrieved using the \textit{BGG} API. 

\section{Methodology}\label{meth}
    The primary goal of this project is to classify comments on board games into predefined categories using semantic parsing techniques. The predefined categories are based on the Italian definition of \href{https://www.goblins.net/goblinpedia}{Goblinpedia}: 
    \begin{enumerate}
        \item \textbf{luck or alea:} all those game elements independent of player intervention, introduced by game mechanics outside the control of the players.
        \item \textbf{bookkeeping}: manual recording of data and potentially automatic or semi-automatic game processes, including also the need of continuosly accessing the rulebook for reference.
        \item \textbf{downtime}: unproductive waiting time between one player turn and the next. By unproductive we mean not only having nothing (or little) to do, but also nothing (or little) to think about.
        \item \textbf{interaction}: the degree of influence that one player's actions have on the actions of the other participants.
        \item \textbf{bash the leader}: when, to prevent the victory of whoever is first, the players are forced to take actions against him, often to the detriment of their own advantage or in any case without gaining anything directly. At the table, the unfortunate situation can arise whereby one or more must "sacrifice" themselves to curb the leader and let the others benefit from this conduct.
        \item \textbf{complicated} vs complex: A game is complicated the more the rules are quantitatively many and qualitatively equipped with exceptions. Once you understand and learn all the variables, a game (that is only) complicated is not difficult to master. In a complicated game, solving a problem leads to immediate, certain and predictable results.\\A game is as complex as the repercussions of one's actions are difficult to predict and master. Even once you understand and learn all the variables, a complex game is still difficult to master. In a complex game, solving one problem leads to other problems.
    \end{enumerate}
    The primary objective of this research is to perform a comprehensive comparison between the unsupervised, non-learning-based method proposed in this study and the \textit{GPT-4o} model developed by OpenAI. The goal is to highlight the strengths and limitations of the proposed methodology in relation to the advanced capabilities of the \textit{GPT-4o} model.
    To achieve this goal, the process starts by parsing the comments to identify their structure, including the different sentences, which are then further parsed to identify the verbs and nouns. Verbs are essential because they typically denote actions or events. Each verb is analyzed in its base form, known as lemmatization, which helps to understand the core action being described. Noun phrases within the sentence are also identified. These phrases often serve as the subject or object associated with the verbs. By linking these noun phrases to their corresponding verbs, potential event concepts are formed. In addition, any adjectives within the noun phrases are included to provide more context for the concept. In cases where noun phrases are associated with auxiliary verbs, which are verbs used in conjunction with a main verb to express tense, mood, or voice, the code accounts for this by forming concepts based on the structure of the auxiliary verb.
    The overall goal is to create a list of unique concepts that encapsulate the events described in the sentence. These concepts are then compiled into a comprehensive list after processing each sentence individually. In this way, the slightly modified method from \cite{10.1145/2487788.2487995}, ensures that all potential event concepts are captured and organized effectively, providing a structured representation of the information contained in the text.\\\\
    To further simplify the extracted concepts, pre-trained word embeddings from \textit{ConceptNet} are used. These embeddings provide a numerical representation of words, capturing semantic similarities based on their contextual usage in a large corpus of text. To represent complex concepts, which are often multi-word expressions, an embedding is computed for each concept by averaging the embeddings of the individual words that make up the concept. This process ensures that each concept is represented as a single, coherent vector in the embedding space. Concepts without valid embeddings (i.e., those not found in the pre-trained embeddings) are excluded from further analysis to maintain the integrity of the representation. The next step is to cluster these concept embeddings to identify groups of semantically related concepts. This is done using the \textit{K-Medoids} algorithm \cite{PARK20093336}, a clustering technique particularly suited to scenarios where representative examples (medoids) from the dataset are preferable to mean-based representatives (centroids). The number of clusters is three, with a dynamic determination when the input number of concepts is less than three, assuming that no more aspects are mentioned in a comment. The clustered concepts are then used for further processing.\\\\
    To classify the concepts into the given classes, an embedding is created by averaging the embeddings of the words that make up the concept. Similarly, each class is represented by an embedding computed from the keywords associated with that class. To determine the similarity between a concept and a class, cosine similarity is used. If the embedding of a concept is sufficiently similar to the embedding of a class (exceeding a specified threshold), the class is considered a potential match for the concept. The classes are then ranked based on their similarity to the concept, and the top matches are identified. For each concept, the class with the highest similarity score is selected, ensuring that each concept is assigned to the class that best represents its meaning.

\section{Results}\label{results}
    \subsection{Experimental Methodology}
    The data used for the experiment consisted of the 100 user comments of the game \textit{Mighty Empires} \cite{mightyempires1990}. To simplify the distance calculation and the resulting classification of the concepts in a comment, the above classes were simplified and reduced to descriptive keywords. The metric used to evaluate and compare the performance of the \textit{GPT-4o} model and the method presented in this study involves manually counting errors. An error is defined as an obviously incorrectly classified aspect, as well as a missing aspect that is present in the comment. This approach allows a direct and clear comparison between the two methods. To capture the aspects generated by the \textit{GPT-4o} model, a simple \textit{CSV-file} is uploaded to the chat. Immediate prompt engineering ensures that the output produced by the \textit{GPT-4o} model mirrors that of the implemented unsupervised method. This output is a combination of the extracted concepts and their classified aspects.

    \subsection{Experimental Results}
    Due to the limitation to one board game, it is not expected that the data represent the aspects equally. It is noticeable that the result of the \textit{GPT} model largely consists of no assignment for the comments. The presented method extracts for most of the comments a significant amount of concepts, most of which are not assigned to an aspect by the similarity calculation. This can be explained by the lack of meaning in some concepts. Regarding the similarity between concepts and aspects, in most cases it does not exceed $0.3$. The manual evaluation of the comments revealed a total of $23$ mapped aspects to the comments, mostly "luck or alea" and "downtime".
    \begin{table}[h!]
        \centering
        \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Metrics} & \textbf{Method} & \textbf{GPT-4o} \\ \hline
        Errors (wrong classified) & 20 & 21 \\ \hline
        Errors (missing) & 15 & 4 \\ \hline
        Correct classifications & 5 & 17 \\ \hline
        \end{tabular}
        \caption{Comparison of the proposed method and \textit{GPT-4o} aspect classifications}
        \label{table:1}
    \end{table}
    A key observation is that, as expected, the \textit{GPT-4o} model performed more accurately with a significantly higher number of correct classifications. In contrast, the presented unsupervised method managed to extract a significant number of concepts from most of the comments, although many of them were incorrect. This indicates a potential problem with the semantic relevance of the extracted concepts, highlighting the challenge of accurately classifying aspects based on the given comments. It is also noteworthy that the correct mappings to the aspects are sometimes not based on the meaning of the concepts, but rather on the chosen similarity comparison, e.g. the concept "play I" is considered similar to the aspect "luck or alea".
        

\section{Conclusion}\label{results}
    The experimental results show that the \textit{GPT-4o} model outperforms the unsupervised method in terms of correct classifications. The superior accuracy of the \textit{GPT-4o} model underscores the progress of training-based algorithms for natural language processing tasks. However, the ability of the unsupervised method to extract numerous concepts suggests potential for refinement in semantic relevance and aspect classification. Future work could focus on improving semantic parsing accuracy by integrating more sophisticated similarity measures or hybrid approaches that combine supervised and unsupervised techniques. In addition, expanding the dataset to include different board games could provide a more comprehensive evaluation of the performance of the methods in different contexts.

\pagebreak


%%=============================================%%
%% For submissions to Nature Portfolio Journals %%
%% please use the heading ``Extended Data''.   %%
%%=============================================%%

%%=============================================================%%
%% Sample for another appendix section			       %%
%%=============================================================%%

%% \section{Example of another appendix section}\label{secA2}%
%% Appendices may be used for helpful, supporting or essential material that would otherwise 
%% clutter, break up or be distracting to the text. Appendices can consist of sections, figures, 
%% tables and equations etc.


%%===========================================================================================%%
%% If you are submitting to one of the Nature Portfolio journals, using the eJP submission   %%
%% system, please include the references within the manuscript file itself. You may do this  %%
%% by copying the reference list from your .bbl file, paste it into the main manuscript .tex %%
%% file, and delete the associated \verb+\bibliography+ commands.                            %%
%%===========================================================================================%%

\bibliography{sn-bibliography}% common bib file
%% if required, the content of .bbl file can be included here once bbl is generated
%%\input sn-article.bbl


\end{document}
